# 客观题

第一纪：语言和火 第二纪：农业和城市 第三纪：文字和车轮 第四纪：机器人和人工智能。**计算机的哲学意义**：可以映照出现实世界中 10 亿个不同的东西，它改变了世界；计算机是中枢神经系统的延伸，可能产生真实意识，发展速度快。**宇宙构成**：一元论（一切都是由单一物质原子组成的）、二元论（宇宙由多个东西组成的）。**我们是什么**：机器、动物或人类。**你的”自我“是什么**：大脑的把戏、一个涌现的思维、你的灵魂。

**制作一个 AI 告诉农民何时播种**：经典 AI，专家系统，机器学习。**古代的机器人、现代的机器人技术是否会终结对工人的需求**：悲观论据（需求终结论）；乐观论据（需求转化论）。**视觉成像**是 AI 机器人面临的第一个问题。**机器人会替代我们做所有工作吗**：机器人和 AI 将替代人类的一切工作；机器人和 AI 将替代“部分”工作；机器人和 AI 不会夺走人们的任何工作机会。**如果我们不能直接计算机器人带来的失业，我们前进的路径又是什么**：不可预测的工作；需要高社交智商的工作；现场工作；需要创造力或抽象思维的工作；还没有人想到的工作。**重大问题**：收入不平等、社会动荡、普遍基本收入。**机器人在战争中应用的核心问题**：是否应该允许机器独立决定杀死谁和放过谁。

**什么是人工智能**：研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门新的技术科学；达特茅斯会议标志着人工智能研究的开始，也是认知科学现代研究的开端。**人工智能的研究方向**：机器思维、机器感知、机器行为。**认知科学的研究范式经历的三次变迁**：算法概念和认知可计算主义研究纲领 (主张“认知的本质就是计算”)、亚符号神经计算：“联结主义”研究范式 (“联结主义”研究范式 - 大脑神经元的活动)、行为主义的研究范式 (感知 - 行动)。**当前人工智能哲学的研究议题**：哲学是对基本和普遍之问题的研究的学科，是关于世界观的理论体系。世界观是关于世界的本质、发展的根本规律、人的思维与存在的根本关系的等普遍基本问题的总体认识，方法论是人类根据世界观形成的认识世界的方法。**科学**大体可以分为三层：基础科学、应用科学、前沿科学。**关于人工智能哲学问题**：我们做出什么样的/该做出什么样的/如何做人工智能；我们做不出“能取代人的人工智能”、可以做出硅基机器人、有可能做出量子机器人；我们该做有形体无遗传的硅基非基因人工智能、无形体有遗传的硅基非基因人工智能。**人工智能为何需要哲学**：第一，思考大问题，澄清基本概念；第二，哲学在不同学科的研究成果之间寻找汇通点，而不受某一具体学科视野之局限；第三，重视论证和辩护，相对轻视证据的约束。**什么是伦理**：伦理是指在处理人与人、人与社会相互关系时应遵循的道理和准则；是指一系列指导行为的观念，是从概念角度上对道德现象的哲学思考；它不仅包含着对人与人、人与社会和人与自然之间关系处理中的行为规范，而且也深刻地蕴涵着依照一定原则来规范行为的深刻道理。**为何科学训练中缺乏哲学训练**：对于处于“学徒期”的科学入门者而言，学会服从既定的研
究范式乃是其第一要务；严格的一级、二级、三级学科分类导致学生们忙于如何熟悉特定领域内的研究规范，而无暇开拓视野，浮想联翩；对于权威科学模式的服从，在很大程度上使大家不愿意接受异说。**人工智能伦理问题**：功利主义、奴化控制、情感伦理、“人”的定义

**解决人工智能威胁论争论的四个困难**：没有统一的模型和测试方法对不同的人工智能系统进行测试；没有统一的模型和测试方法能够同时对人工智能系统和人类进行测试；人工智能系统没有形成智力发展水平测试的标准输入输出接口；没有关于人工智能智力发展水平的历史测试统计数据。**对图灵测试的诘难**：模拟的智能是否是真正的智能？智能必须以语言作为中介吗?语言行为是否足够覆盖智能的多样性？基于语句的判断和推理是否抓住了智能的本质？**对图灵测试的反驳**：人类中心主义，香农麦卡锡反驳。**中文屋论证**：提供所有知识与工具来回应，并不能证明有智能。**超计算**：是一个研究比图灵机计算能力更强的计算能力的计算机器的理论计算机科学分支，包含：谕示机（根据给定可以是任何复杂度类之内的问题，在单一运算之内解答特定问题）、BBS 机（可以在实数域内计算并可以储存无限精度的实数）、邱奇图灵论题（所有计算或算法都可以由一台图灵机来执行）。**哥德尔不完备性定理（图灵机等价说法）**：任何一致的数学形式系统都包含不可判定命题；没有数学形式系统既是一致的又是完全的；没有定理证明机器（或机器程序）能够证明数学中所有的真命题；数学是算法不可穷尽的（数学是算法不可完全的）。**德雷福斯从现象学的视角出发，认为人工智能有其限度**：第一层是对功能主义的问题求解范式的人工智能的批判；第二层是对联结主义的机器学习范式的人工智能的批判

**AGI**：是具备与人类同等智能、或超越普通人类的人工智能，能表现正常人类所具有的所有智能行为。**人类大脑**：要想成就真正的智能，它还必须有心灵。**心灵**：心灵是情感、想象力、判断力、智力、决断力和意志力的源泉，“心灵”使得构建 AGI 变得更加困难。**我们什么时候能实现 AGI**：推测我们将在 10 年内拥有 AGI 的人是那些“认为智能简单、创造力并不特别、我们已经走上构建 AGI 之路、AGI 很快就会实现自我发展”的人。那些声称我们离造出 AGI 还有 500 年之遥的人则认为智能具有先天的困难性，人类的精神能力也非同寻常，他们相信我们甚至还没有开始走上正确的构建 AGI 之路。

**计算机意识**：感知能力的定义：感知能力是指计算机对外部环境的理解和反应；感知能力的实现方式：通过传感器和算法，计算机可以模拟人类的感知过程；感知能力在人工智能中的应用：感知能力是人工智能实现自主决策和行动的关键；自由意志的定义：自由意志是指个体在思考和行动时不受外在强制，能够自主选择的能力；自由意志与人工智能:探讨自由意志是否适用于人工智能，以及人工智能是否能拥有真正的自由意志；自由意志的哲学争议:分析自由意志在哲学领域的争议，包括决定论、随机性等观点。**意识**：它是主观体验的感触，是你第一人称的知觉。**各大意识理论**：弱涌现、强涌现、量子现象、物质的物理属性、意识是基本原理、意识是普遍的、大脑的把戏、精神上的事物。

**强人工智能的界定**：强人工智能观点认为计算机不仅是用来研究人的思维的一种工具；相反，只要运行适当的程序，计算机本身就是有思维的。**弱人工智能的界定**：弱人工智能观点认为不可能制造出能真正地推理和解决问题的智能机器，这些机器只不过看起来像是智能的，但是并不真正拥有智能，也不会有自主意识。

**机器人三大法则**：机器人不得伤害人，或看到人受到伤害而袖手旁观；在不违反第一定律的前提下，机器人必须绝对服从人类给与的任何命令；在不违反第一定律和第二定律的前提下，机器人必须尽力保护它自己；机器人不得伤害整体人类，或坐视整体人类受到伤害。**IEEE 的人工智能伦理报告**：一般原则：适用于所有类型的人工智能和自主系统，需要考虑的三大因素：体现人权、优先考虑最大化对人类和自然环境的好处、削弱人工智能的风险和负面影响；人类利益原则：要求考虑如何确保 AI 不侵犯人权；责任原则：涉及如何确保 AI 是可以被问责的。为了解决过错问题，避免公众困惑，AI 系统必须在程序层面具有可责性，证明其为什么以特定方式运作；透明性原则：意味着自主系统的运作必须是透明的。AI 是透明的意味着人们能够发现其如何以及为何做出特定决定。**人工智能的道德约束机制**：机器化系统，智能系统和自动系统的伦理推动标准、自动和半自动系统的故障安全设计标准、道德化的人工智能和自动系统的福祉衡量标准。**四个维度看伦理挑战**：人工智能的自主性、非透明性、拓展性、垄断性。**AI 决策三大问题**：公平、透明性、可责性。**机器学的哪三个阶段中的伦理问题**：数据收集、模型建构、模型使用。**哲学讨论**：道德主义认为人是目的不是工具，功利主义看数量

**道德责任**是人们对自己行为的过失及其不良后果在道义上所承担的责任。**道德能动性**：广义指对外界或内部的刺激或影响作出积极的、有选择的反应或回答；狭义指意向性的行动，人的能动性，它往往与自由意志、意识和意向性等概念相联系，具有自觉性、目的性和计划性等特点。**什么是道德能动者**：正面说 ANT 或者广义，反面说狭义。
