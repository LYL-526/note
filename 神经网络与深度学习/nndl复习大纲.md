# 复习大纲

## 一、绪论

- 人工智能背景与意义
- 万能逼近定理
- 神经网络发展历程
- 深度学习三步骤：
  - 定义网络
  - 损失函数
  - 优化
- 常用深度学习框架举例与其特点

## 二、机器学习概述

### 机器学习部分

- 经验风险最小化与结构风险最小化
- 机器学习三要素：
  - 模型
  - 学习准则
  - 优化
- 三大基本任务：回归，分类，聚类
- 常见损失函数：0/1 损失，平方损失等
- 随机梯度下降算法（简答）
- 正则化方法：加正则化项（l1/l2 约束），早停，Dropout，数据集增强，权重衰减
- 经验风险最小化等价于最大似然估计，结构风险最小化等价于最大后验估计（证明）

### 神经网络部分

- FNN,CNN,RNN 反向传播算法（简答）
- 优化问题
  - 难点
    - 参数过多，影响训练
    - 非凸优化问题：存在局部最优解，影响迭代
    - 梯度消失问题，下层参数难调
    - 参数解释比较困难
  - 需求
    - 计算资源要大
    - 数据要多
    - 算法效率要好：即收敛快
- 梯度消失与梯度爆炸，定义与避免方法
- 长程依赖问题与改进方法

### 网络优化与正则化

- 网络优化难点与改进方法
- 梯度方向优化，动量法，理解即可（了解，没法细考）
- 参数不能初始化为 0，对称权重问题（简答）
- 超参数有哪些，优化方法
- 正则化方法具体的原理与操作

## 三、无监督学习

### 无监督学习概述

- 无监督学习主要任务
  - 聚类
  - 特征学习
  - 密度估计
- 参数估计与非参数估计的特点与应用场景（简答）
  - 非参数估计（除了直方图）需要保存整个数据集
  - 参数估计不需要保存整个数据集，因此在计算和存储上更高效
- 主成分分析 PCA
  - 缺点：线性，无监督类型的学习
  - 适合的数据
- 线性编码含义
- ~~稀疏编码~~（了解，基本确定不考）
- 自编码器原理及变形方式：稀疏，降噪，变分（简答）
- 自监督学习含义（了解）

### 模型独立学习

- 学习方式（7 挑 4 说概念，简答/填空）

## 四、注意力机制

- 软性注意力机制打分模型（计算）
- 多头自注意力机制
- 自注意力机制与 CNN、RNN 之间的关系（简答）
- Transformer 完整网络（简答）

## 五、概率图模型与参数估计

- 贝叶斯网络
- 局部马尔可夫性
- 朴素贝叶斯公式
- MLE,MAP 之间的关系
- EM 算法完整推导，凑 KL 散度方法（两步）
- 重要性采样
- VAE 与 AE 的不同点
- SGVB 重参数化作用

## 六、深度判别模型与应用

- 判别模型与生成模型的区别并举例
- 判别模型无法转换为生成式模型，而生成式模型可以转换为判别式
- Two Stage 与 One Stage 概念、区别与优劣性
- 目标检测、语义分割、实例分割概念与区别
- 点云模型的置换不变性与变换不变性
- 点云分类模型 Pointnet, Pointnet++(了解，不考)
- 图结构建模
  - 邻居聚合机制流程,包括名词解释如：k 跳，Agg 等

## 七、强化学习

- 智能体和环境的概念
- 绘制智能体与环境交互的流程图
- 马尔可夫过程，给图写条件概率/联合概率，或者给概率画图
- 强化学习的目标是学习到一个策略 $\pi \theta (a|s)$ 来**最大化期望回报**
- 状态 - 值函数和状态 - 动作值函数的概念
- 策略梯度算法， $J(\theta)$ 的公式
  - 考法：填写如何引入 $log$ 来证明公式
  - $\frac{\partial}{\partial \theta}logp_{\theta}(\tau)$ 是和状态转移概率无关，只和策略函数相关

## 其他

- 所有实验的理论与操作过程（简答题）
- 所有布置过的作业（简答题，计算题）

## 必考

- 发展历程
- 梯度下降法（完整算法）
- 反向传播算法（完整算法）
- 梯度爆炸/消失
- 正则化细节
- 模型独立学习 7 选 4
- 自注意力机制算分数
- 自注意力机制与 CNN、RNN 之间的关系
- Transformer
- 策略梯度算法
